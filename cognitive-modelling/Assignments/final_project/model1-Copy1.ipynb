{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODEL 1\n",
    "#### Name: Manuel Alejandro Delgadillo Ferrel\n",
    "#### Student number: S4400151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model import Model\n",
    "from dmchunk import Chunk\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time conversion functions\n",
    "def noise(s):\n",
    "    rand = random.uniform(0.001,0.999)\n",
    "    return s * math.log((1 - rand)/rand)\n",
    "\n",
    "def time_to_pulses(time, t_0 = 0.011, a = 1.1, b = 0.015):\n",
    "    pulses = 0\n",
    "    pulse_duration = t_0\n",
    "    while time >= pulse_duration:\n",
    "        time = time - pulse_duration\n",
    "        pulses += 1\n",
    "        pulse_duration = a * pulse_duration + noise(b * a * pulse_duration)\n",
    "    return pulses\n",
    "\n",
    "def pulses_to_time(pulses, t_0 = 0.011, a = 1.1, b = 0.015):\n",
    "    time = 0\n",
    "    pulse_duration = t_0\n",
    "    while pulses > 0:\n",
    "        time = time + pulse_duration\n",
    "        pulses = pulses - 1\n",
    "        pulse_duration = a * pulse_duration + noise(b * a * pulse_duration)\n",
    "    return time\n",
    "\n",
    "#Functions for standard deviation\n",
    "def variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data)/n\n",
    "    return sum((x-mean)**2 for x in data) / (n-ddof)\n",
    "def stdev(data):\n",
    "    var = variance(data)\n",
    "    std_dev = math.sqrt(var)\n",
    "    return std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up initial values\n",
    "participants = 10\n",
    "conditions = 2\n",
    "TrainingTrials = 500\n",
    "MaxTrials = 1500\n",
    "\n",
    "short_inter = np.linspace(450, 825, num=6)\n",
    "long_inter = np.linspace(750, 1125, num=6)\n",
    "medium_inter = np.linspace(600, 975, num=6)\n",
    "\n",
    "#Only for probability values\n",
    "i = 1/6\n",
    "chance = [i for j in range(6)]\n",
    "\n",
    "#The 675 ms interval occurred with more frequency\n",
    "probability = {\"Short Uniform\": chance,\n",
    "               \"Long Uniform\": chance,\n",
    "               \"Uniform\": chance,\n",
    "               \"Peaked\": [1/12, 7/12, 1/12, 1/12, 1/12, 1/12]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([450., 525., 600., 675., 750., 825.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only for observing purposes\n",
    "short_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 750.,  825.,  900.,  975., 1050., 1125.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([600., 675., 750., 825., 900., 975.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<dmchunk.Chunk object at 0x0000025D3722B4F0>: 0.4518594442752588}\n",
      "[<dmchunk.Chunk object at 0x0000025D3722B4F0>, <dmchunk.Chunk object at 0x0000025D3722B700>]\n",
      "1.0\n",
      "{<dmchunk.Chunk object at 0x0000025D3722B4F0>: -0.682887008275895, <dmchunk.Chunk object at 0x0000025D3722B970>: 0.16474313138843336}\n",
      "[<dmchunk.Chunk object at 0x0000025D3722B4F0>, <dmchunk.Chunk object at 0x0000025D3722B700>, <dmchunk.Chunk object at 0x0000025D3722B970>]\n",
      "0.9857711228407678\n",
      "{<dmchunk.Chunk object at 0x0000025D3722B4F0>: -1.0299923995536162, <dmchunk.Chunk object at 0x0000025D3722B970>: -0.7680451419393013, <dmchunk.Chunk object at 0x0000025D3722BBE0>: 0.025208071191938557}\n",
      "[<dmchunk.Chunk object at 0x0000025D3722B4F0>, <dmchunk.Chunk object at 0x0000025D3722B700>, <dmchunk.Chunk object at 0x0000025D3722B970>, <dmchunk.Chunk object at 0x0000025D3722BBE0>]\n",
      "0.9765082710780166\n",
      "{<dmchunk.Chunk object at 0x0000025D3722B4F0>: -1.2389263071218553, <dmchunk.Chunk object at 0x0000025D3722B970>: -1.0825909665538465, <dmchunk.Chunk object at 0x0000025D3722BBE0>: -0.8067779652428415, <dmchunk.Chunk object at 0x0000025D3722BE80>: 0.011236150257059456}\n",
      "[<dmchunk.Chunk object at 0x0000025D3722B4F0>, <dmchunk.Chunk object at 0x0000025D3722B700>, <dmchunk.Chunk object at 0x0000025D3722B970>, <dmchunk.Chunk object at 0x0000025D3722BBE0>, <dmchunk.Chunk object at 0x0000025D3722BE80>]\n",
      "0.977630052096365\n",
      "{<dmchunk.Chunk object at 0x0000025D3722B4F0>: -1.380815001678933, <dmchunk.Chunk object at 0x0000025D3722B970>: -1.2678852618263805, <dmchunk.Chunk object at 0x0000025D3722BBE0>: -1.0947418391237647, <dmchunk.Chunk object at 0x0000025D3722BE80>: 0.4683938019198402}\n",
      "[<dmchunk.Chunk object at 0x0000025D3722B4F0>, <dmchunk.Chunk object at 0x0000025D3722B700>, <dmchunk.Chunk object at 0x0000025D3722B970>, <dmchunk.Chunk object at 0x0000025D3722BBE0>, <dmchunk.Chunk object at 0x0000025D3722BE80>]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "<dmchunk.Chunk object at 0x0000025D34521040>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-26d5349299bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mpattern\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"retreiving-goal\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslots\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"isa\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"time-fact\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlatency\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve_blended_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pulses\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mr_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_retrieval_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Univ\\Courses\\1b\\CognitiveModelling\\Assignments\\final_project\\model.py\u001b[0m in \u001b[0;36mget_retrieval_probability\u001b[1;34m(self, chunk, pattern)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;33m/\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: <dmchunk.Chunk object at 0x0000025D34521040>"
     ]
    }
   ],
   "source": [
    "#Heading of the dataframe\n",
    "count = 0\n",
    "df = pd.DataFrame(columns = [\"int\", \"resp\",\"Subject\", \"Block\", \"Run\", \"Task\", \"Main\"])\n",
    "\n",
    "for Subject in range(1, participants+1):\n",
    "    if Subject <= 4:\n",
    "        conditions = {\"Short Uniform\": short_inter,\n",
    "                      \"Long Uniform\": long_inter}\n",
    "        Task=1\n",
    "    else:\n",
    "        conditions = {\"Uniform\": medium_inter,\n",
    "                      \"Peaked\": medium_inter}\n",
    "        Task=2\n",
    "    for cond in conditions:\n",
    "        m = Model()\n",
    "        main = False\n",
    "                \n",
    "        #trials ranging from 500 to 1500\n",
    "        train_trials = np.random.randint(TrainingTrials, MaxTrials)\n",
    "            \n",
    "        #sessions were divided into 2 trials\n",
    "        TestTrials = train_trials + MaxTrials - TrainingTrials\n",
    "            \n",
    "        for trial in range(TestTrials):\n",
    "            #initial 1s\n",
    "            m.time += 1\n",
    "               \n",
    "            #interval for each condition (short, long, uniform and peaked)\n",
    "            interval = np.random.choice(conditions[cond], p = probability[cond])\n",
    "            m.time += interval /1000\n",
    "            pulses = time_to_pulses(interval / 1000)\n",
    "                \n",
    "            #Yellow dot appears on the screen for at least 185 ms which varies from trial to trial\n",
    "            m.time += np.random.uniform(0.0185, 0.02)\n",
    "            \n",
    "            #Input Chunk\n",
    "            fact = Chunk(name = \"tf\" + str(pulses), slots ={\"isa\":\"time-fact\", \"pulses\" : pulses})\n",
    "            m.add_encounter(fact)\n",
    "                \n",
    "            #wait for at least 250ms after the flash\n",
    "            m.time += np.random.uniform(0.25, 1)\n",
    "                \n",
    "            #time interval\n",
    "            pattern = Chunk(name = \"retreiving-goal\", slots = {\"isa\":\"time-fact\"})\n",
    "            t,latency = m.retrieve_blended_trace(pattern, \"pulses\")\n",
    "            r_prob = m.get_retrieval_probability(fact, pattern)\n",
    "            print(r_prob)\n",
    "\n",
    "            time = pulses_to_time(t)\n",
    "            m.time += pulses_to_time(t)\n",
    "            time = (pulses_to_time(t))*1000\n",
    "                \n",
    "            #delay of 450ms-850ms before feedback\n",
    "            m.time += np.random.uniform(0.45, 0.85)\n",
    "                \n",
    "            #displaying of the performance for 62ms\n",
    "            m.time += 0.062\n",
    "                \n",
    "            #Recording of the training was necessary for observing purposes\n",
    "            if trial > train_trials:\n",
    "                main = True\n",
    "                df.loc[count] = [interval,time,Subject,cond,trial + 1,Task,main]\n",
    "                count += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"model.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting of the data found during the experiments for response bias values\n",
    "def plot_exp1(df, interval_1, interval_2):\n",
    "    df = df[df[\"Main\"] == True]\n",
    "    intervals = df[df[\"Block\"].isin([interval_1, interval_2])]\n",
    "\n",
    "    fig = plt.figure(figsize = (20, 7))\n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax2 = fig.add_subplot(132)\n",
    "\n",
    "    #Experiment for single subjects\n",
    "    first_subject = intervals[\"Subject\"].unique()[0]\n",
    "    X = intervals[intervals[\"Subject\"] == first_subject]\n",
    "\n",
    "    a1 = X[X[\"Block\"] == interval_1]    \n",
    "    a1 = a1.groupby([\"int\"])[\"resp\"].mean().reset_index()\n",
    "    a1[\"bias\"] = a1[\"resp\"] - a1[\"int\"]\n",
    "\n",
    "    a2 = X[X[\"Block\"] == interval_2]    \n",
    "    a2 = a2.groupby([\"int\"])[\"resp\"].mean().reset_index()\n",
    "    a2[\"bias\"] = a2[\"resp\"] - a2[\"int\"]\n",
    "\n",
    "    ax1.scatter(a1[\"int\"], a1[\"bias\"], s=50, c='firebrick', marker=\".\", label=interval_1)\n",
    "    ax1.scatter(a2[\"int\"], a2[\"bias\"], s=50, c='lawngreen', marker=\".\", label=interval_2)\n",
    "    ax1.axhline(y=0, color='gray', linestyle='-')\n",
    "    ax1.set(xlabel = \"Physical time interval (ms)\", ylabel = \"Response Bias (ms)\")\n",
    "    ax1.set_title(\"Single Subject\")\n",
    "\n",
    "    #Experiment for a group of subjects\n",
    "    a1 = intervals[intervals[\"Block\"] == interval_1]    \n",
    "    a1 = a1.groupby([\"int\"])[\"resp\"].mean().reset_index()\n",
    "    a1[\"bias\"] = a1[\"resp\"] - a1[\"int\"]\n",
    "\n",
    "    a2 = intervals[intervals[\"Block\"] == interval_2]    \n",
    "    a2 = a2.groupby([\"int\"])[\"resp\"].mean().reset_index()\n",
    "    a2[\"bias\"] = a2[\"resp\"] - a2[\"int\"]\n",
    "\n",
    "    ax2.scatter(a1[\"int\"], a1[\"bias\"], s=50, c='firebrick', marker=\".\", label=interval_1)\n",
    "    ax2.scatter(a2[\"int\"], a2[\"bias\"], s=50, c='lawngreen', marker=\".\", label=interval_2)\n",
    "    ax2.axhline(y=0, color='gray', linestyle='-')\n",
    "    ax2.set(xlabel = \"Physical time interval (ms)\", ylabel = \"Response Bias (ms)\")\n",
    "    ax2.set_title(\"Group Mean\")\n",
    "    \n",
    "    ax1.legend(loc='upper right')\n",
    "    ax2.legend(loc = 'upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting of the data found during the experiments for response standard deviation values\n",
    "def plot_exp2(df, interval_1, interval_2):\n",
    "    df = df[df[\"Main\"] == True]\n",
    "    intervals = df[df[\"Block\"].isin([interval_1, interval_2])]\n",
    "\n",
    "    fig = plt.figure(figsize = (20, 7))\n",
    "    ax1 = fig.add_subplot(131)\n",
    "    ax2 = fig.add_subplot(132)\n",
    "\n",
    "    #Experiment for single subjects\n",
    "    first_subject = intervals[\"Subject\"].unique()[0]\n",
    "    X = intervals[intervals[\"Subject\"] == first_subject]\n",
    "\n",
    "    a1 = X[X[\"Block\"] == interval_1]    \n",
    "    a1 = a1.groupby([\"int\"])[\"resp\"].std().reset_index()\n",
    "    a1[\"bias\"] =stdev(a1[\"resp\"] - a1[\"int\"])\n",
    "    \n",
    "    a2 = X[X[\"Block\"] == interval_2]    \n",
    "    a2 = a2.groupby([\"int\"])[\"resp\"].std().reset_index()\n",
    "    a2[\"bias\"] =stdev(a1[\"resp\"] - a1[\"int\"])\n",
    "    \n",
    "    ax1.scatter(a1[\"int\"], a1[\"bias\"], s=50, c='firebrick', marker=\".\", label=interval_1)\n",
    "    ax1.scatter(a2[\"int\"], a2[\"bias\"], s=50, c='lawngreen', marker=\".\", label=interval_2)\n",
    "    ax1.axhline(y=0, color='gray', linestyle='-')\n",
    "    ax1.set(xlabel = \"Physical time interval (ms)\", ylabel = \"Response sd (ms)\")\n",
    "    ax1.set_title(\"Single Subject\")\n",
    "\n",
    "    #Experiment for a group of subjects\n",
    "    a1 = intervals[intervals[\"Block\"] == interval_1]    \n",
    "    a1 = a1.groupby([\"int\"])[\"resp\"].std().reset_index()\n",
    "    a1[\"bias\"] =stdev(a1[\"resp\"] - a1[\"int\"])\n",
    "    \n",
    "    a2 = intervals[intervals[\"Block\"] == interval_2]    \n",
    "    a2 = a2.groupby([\"int\"])[\"resp\"].std().reset_index()\n",
    "    a2[\"bias\"] =stdev(a1[\"resp\"] - a1[\"int\"])\n",
    "    \n",
    "    ax2.scatter(a1[\"int\"], a1[\"bias\"], s=50, c='firebrick', marker=\".\", label=interval_1)\n",
    "    ax2.scatter(a2[\"int\"], a2[\"bias\"], s=50, c='lawngreen', marker=\".\", label=interval_2)\n",
    "    ax2.axhline(y=0, color='gray', linestyle='-')\n",
    "    ax2.set(xlabel = \"Physical time interval (ms)\", ylabel = \"Response sd (ms)\")\n",
    "    ax2.set_title(\"Group Mean\")\n",
    "    \n",
    "    ax1.legend(loc='center right')\n",
    "    ax2.legend(loc = 'center right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exp1(df, \"Short Uniform\", \"Long Uniform\")\n",
    "plot_exp2(df, \"Short Uniform\", \"Long Uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_exp1(df, \"Uniform\", \"Peaked\")\n",
    "plot_exp2(df, \"Uniform\", \"Peaked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I tried using the standard deviation mean but it vary from -80 to 100 so it didnt make much sense compared to the Acerbi\n",
    "#experiment, so I left it as the mean standard deviation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
